= Discriminative AI for Healthcare
A *Discriminative* AI model is a narrow, task-specific model that is designed to perform a specific function, such as classifying images or predicting outcomes based on input data.

== Applications
In many cases, computer vision models are used to find patterns in medical images that can help with diagnosis, prognosis, and treatment planning. Some common applications include:
- Cardiac Ultrasound
- 4D Flow MRI
- Cardiac MRI

In clinical notes, natural language processing (NLP) techniques are used to extract relevant information from unstructured text data.

A *Benchmark Dataset* is a standardized dataset that is used to evaluate and compare the performance of different AI models. 

== Generative AI Models
*Generative AI* models are designed to create new content, such as images, text, or audio, based on patterns learned from training data. It learns the underlying distribution of the data and can generate new samples that are similar to the training data.

== Fidelity and Diversity
- *Fidelity* refers to how closely the generated content resembles real-world data. High-fidelity models produce outputs that are realistic and indistinguishable from real data.
- *Diversity* refers to the variety of outputs that a generative model can produce. A diverse model can generate a wide range of different samples, rather than producing similar or repetitive outputs.
  #align(center)[
    #image("../images/fidelity_diversity.png")
  ]

== Human Evaluation of Generative Models
Evaluating generative models often involves human judgment to assess the quality and relevance of the generated content. This can include:
- *Visual Turing Test*: Human evaluators are asked to distinguish between real and generated images.
- *Clinical Relevance Assessment*: Experts evaluate whether the generated medical data is clinically useful and accurate.
- *Diversity Assessment*: Evaluators assess the variety of outputs produced by the model.


